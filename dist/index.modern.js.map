{"version":3,"file":"index.modern.js","sources":["../src/helpers/helpers.js","../src/classes/Interpolator.js","../src/helpers/geometry.js","../src/classes/InterpolatedDetector.js","../src/classes/Detectors/__VectorDetector.js","../src/classes/Detectors/VDBlaze.js","../src/constants.js","../src/classes/Detectors/VDMesh.js","../src/classes/Detectors/VDIrisMesh.js","../src/classes/Detectors/VDHandpose.js","../src/helpers/mapDeep.js","../src/helpers/tfStepTowardFactory.js","../src/defaultsMULTI.js","../src/nosePoseMULTI.js"],"sourcesContent":["/**\n * Simple object check.\n * @param item\n * @returns {boolean}\n */\nfunction isObject(item) {\n  return item && typeof item === 'object' && !Array.isArray(item);\n}\n\n/**\n * Deep merge two objects.\n * @param target\n * @param ...sources\n */\nfunction mergeDeep(target, ...sources) {\n  if (!sources.length) return target;\n  const source = sources.shift();\n\n  if (isObject(target) && isObject(source)) {\n    for (const key in source) {\n      if (isObject(source[key])) {\n        if (!target[key]) Object.assign(target, { [key]: {} });\n        mergeDeep(target[key], source[key]);\n      } else {\n        Object.assign(target, { [key]: source[key] });\n      }\n    }\n  }\n\n  return mergeDeep(target, ...sources);\n}\n\nexport { mergeDeep };\n","// takes a slow promise and allows it to be run quickly with values interpolated (using any function) when slow promise  has yet to return\n\n// slowPromise :FUNCTION returns a promise that takes some time to resolve\n// stepToward : FUNCTION called on previous calculated value and resolved value of promise\n// fps : frames per second for slowPromise to be called (leave as false if max fps for promise is desired)\n\nexport default class Interpolator {\n  constructor(slowPromise, stepToward, fps = false) {\n    this.slowPromise = slowPromise;\n    this.stepToward = stepToward;\n    this.fast = null; //updated every iteration call (note: here it is the whole prediction object -  see defaults)\n    this.slow = null; //updated only when promise resolves\n    this.resolved = true;\n    this.fps = fps;\n  }\n\n  interpolate(val) {\n    this.__updateSlow(val);\n    this.__updateFast();\n    return this.fast;\n  }\n  __updateFast() {\n    if (!this.fast) {\n      this.fast = this.slow;\n    } else {\n      this.fast = this.stepToward(this.fast, this.slow); // current val, target val, 'sensitiviy' (some const)\n    }\n  }\n  async __updateSlow(val) {\n    if (!this.resolved) {\n      return;\n    }\n    if (this.resolved) {\n      this.resolved = false;\n      let v;\n\n      if (this.fps) {\n        /**\n         note: if the slowPromise resolves much more quickly than the timeout(fps) then\n         there there is a delay and what is returned can be 'stale'\n         i.e. here the detection will be from too many frames ago and be delayed\n         */\n        //\n        const [p1, p2] = [this.slowPromise(val), this.__timeoutPromise()];\n        let p = await Promise.all([p1, p2]);\n        v = p[0];\n        this.resolved = true;\n        v && (this.slow = v);\n      } else {\n        v = await this.slowPromise(val);\n        this.resolved = true;\n        v && (this.slow = v);\n      }\n    }\n  }\n\n  // helper to enforce fps minimum\n  async __timeoutPromise() {\n    // console.log('calling TO');\n    return new Promise((resolve, reject) => {\n      setTimeout(resolve, 1000 / this.fps);\n    }).then(() => {\n      // console.log('resolved TO');\n      return null;\n    });\n  }\n}\n","// not quite the same as normal tween functions? - we don't track the intial value..\n\n//   // step size range [0,1] (percent of total dist)\nfunction stepToward(prevPos, actualPos, stepSize = 0.1) {\n  let x, y;\n  let [x1, y1] = [...prevPos];\n  let [x2, y2] = [...actualPos];\n\n  let d_x = x2 - x1;\n  let d_y = y2 - y1;\n\n  x = x1 + d_x * stepSize;\n  y = y1 + d_y * stepSize;\n  return [x, y];\n}\n\n// rename stepToward1D and above stepToward2D\nfunction stepTowardLinear(prevVal, actualVal, stepSize = 0.1) {\n  let d_x = actualVal - prevVal;\n\n  return prevVal + d_x * stepSize;\n}\n\nfunction averageCoordinate(array) {\n  let l = array.length;\n  let c = array\n    .reduce(\n      (acc, curr) => {\n        let [x, y, z] = acc;\n        let [xc, yc, zc] = curr;\n        return [x + xc, y + yc, z + zc];\n      },\n      [0, 0, 0]\n    )\n    .map((v) => v / l);\n  return c;\n}\n\nfunction distanceCoordinates(c1, c2) {\n  if (c1.length === 2) {\n    return Math.sqrt((c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2);\n  } else if (c1.length === 3) {\n    return Math.sqrt(\n      (c2[0] - c1[0]) ** 2 + (c2[1] - c1[1]) ** 2 + (c2[2] - c1[2]) ** 2\n    );\n  } else {\n    throw new Error('please enter 2d or 3d vectors');\n  }\n}\n\n// This maths is absolutely terrible\nfunction angleCoordinatesXY(c1, c2) {\n  let [x1, y1] = c1;\n  let [x2, y2] = c2;\n  let d_x = x2 - x1;\n  let d_y = y2 - y1;\n  let angle = Math.atan(d_y / d_x);\n  let a;\n  a = angle < 0 ? angle + Math.PI : angle;\n  return Math.PI - a;\n}\n\nfunction stepToward2D(prevPos, actualPos, stepSize = 0.1) {\n  let x, y;\n  let [x1, y1] = [...prevPos];\n  let [x2, y2] = [...actualPos];\n\n  let d_x = x2 - x1;\n  let d_y = y2 - y1;\n\n  x = x1 + d_x * stepSize;\n  y = y1 + d_y * stepSize;\n  return [x, y];\n}\n\nfunction stepToward1D(prevVal, actualVal, stepSize = 0.1) {\n  let d_x = actualVal - prevVal;\n\n  return prevVal + d_x * stepSize;\n}\n\nexport {\n  stepToward1D,\n  stepToward2D,\n  stepToward,\n  stepTowardLinear,\n  averageCoordinate,\n  distanceCoordinates,\n  angleCoordinatesXY,\n};\n","import { mergeDeep } from './../helpers/helpers';\nimport Interpolator from './Interpolator';\nimport { defaults } from '../defaults';\nimport { stepToward } from '../helpers/geometry';\n\n//\n\n// params\n// detector: a detector with load, detect and configure function\n// configs: e.g. :\n\nexport default class InterpolatedDetectorMULTI {\n  constructor(detectors) {\n    // {noser: {detector: NVDDetector(class), config:{}}, mesh: {detector: NVDDetector(class), config:{}}, etc }\n    this.detectors = detectors;\n    this.loaded = false;\n    this.animationFrameId = null;\n  }\n\n  async load() {\n    let promises = [];\n    Object.values(this.detectors).forEach((d) => {\n      // Load the models\n      promises.push(d.detector.load());\n      // await d.detector.load();\n\n      // Add the interpolators\n\n      const { stepperFactory, mapperArgs, fps } = d.config.interpolator;\n      const interpolatorFunction = stepperFactory(mapperArgs);\n\n      d.interpolator = new Interpolator(\n        (video) => d.detector.detect(video), //slow fn to interpolate between return vals\n        interpolatorFunction, //interpolation fn\n        fps\n      );\n    });\n    let p = await Promise.all(promises);\n    console.log('all loaded');\n    this.loaded = true;\n  }\n\n  configure(configs) {\n    let detNames = Object.keys(configs);\n    detNames.forEach((d) => {\n      // get detector\n      let dd = this.detectors[d];\n      // configure the detector if config\n      if (configs[d].detector) {\n        this.__configureDetector(configs[d].detector, dd);\n      }\n      // configure the interpolator if config\n      if (configs[d].interpolator) {\n        this.__configureInterpolator(configs[d].interpolator, dd);\n      }\n    });\n  }\n\n  // probably bad naming -  actually calls the interpolators (which in turn call the detect fn of detectors as their 'slow' promise)\n  detect(video) {\n    if (!this.loaded) {\n      return {};\n    }\n    let detections = {};\n    Object.keys(this.detectors).forEach((n) => {\n      detections[n] = this.detectors[n].interpolator.interpolate(video);\n    });\n\n    // let configs = Object.values({ ...this.detectors }).map((v) => v.config);\n    let configs = {};\n    Object.keys(this.detectors).forEach((n) => {\n      configs[n] = this.detectors[n].config;\n    });\n\n    return { detections, configs };\n  }\n\n  // looping detection\n  startDetection(video, loopers = []) {\n    const looper = () => {\n      let d = this.detect(video);\n      //loop any functions hooking into the animation loop\n      if (loopers.length) {\n        loopers.forEach((fn) => fn(d));\n      }\n      this.animationFrameId = requestAnimationFrame(looper);\n    };\n    looper();\n  }\n\n  stopDetection() {\n    cancelAnimationFrame(this.animationFrameId);\n  }\n  __configureDetector(config, detector = {}) {\n    Object.assign(detector.config.detector, config);\n    detector.detector.configure(config);\n  }\n\n  // interpolator doesn't (yet?) have config option so need to instantiate new one\n  __configureInterpolator(config, detector = {}) {\n    mergeDeep(detector.config.interpolator, config);\n\n    const { stepperFactory, mapperArgs, fps } = detector.config.interpolator;\n    const interpolatorFunction = stepperFactory(mapperArgs);\n\n    detector.interpolator = new Interpolator(\n      (video) => detector.detector.detect(video), //slow fn to interpolate between return vals\n      interpolatorFunction, //interpolation fn\n      fps\n    );\n  }\n}\n\n","  import { FACE_SCALE } from '../../constants';\n\nexport default class VectorDetector {\n  constructor(config) {\n    this.model = null;\n    this.config = config; // optional - can be configured after init\n  }\n\n  // load, detect and __getPredictionData are in extensions of this class\n\n  configure(config) {\n    Object.assign(this.config, config);\n    //\n  }\n\n  // TODO: move this to face classes (or a shared class for all face classes? - which blaze/mesh inherit from)\n  __getNosePointVectors(nose, center, scale = 1) {\n    let central_bounding = this.config.central_bounding;\n    let outer_bounding = this.config.outer_bounding;\n\n    const x = center[0] - nose[0];\n    const y = center[1] - nose[1];\n    let coords = [x, y];\n\n    //normalize distance\n\n    // -----------------------------------------------------------\n\n    const direction_word = this.__getDirection(coords, central_bounding);\n    const vector = [x, y];\n\n    // TODO - should outerbounding be scaled separately?\n    const nose_normalized_square = this.__getVectorNormalized(\n      coords, //px\n      outer_bounding, //px\n      scale //px used to grow/shrink bounding limits based on z distance\n    );\n    const nose_normalized_circle = this.__normalizeRect2Circ(\n      nose_normalized_square\n    );\n\n    return {\n      direction_word,\n      vector, //absolute value in face bounding rect\n      nose_normalized_square, //normalized square [0,1]x [0,1]y\n      nose_normalized_circle, //normalized circle [0,1]r\n    };\n  }\n\n  __normalizeInRange(value, range1, range2 = [0, 1]) {\n    if (value > range1[1]) {\n      return range2[1];\n    }\n    if (value < range1[0]) {\n      return range2[0];\n    }\n    let dist1 = range1[1] - range1[0];\n    let dist2 = range2[1] - range2[0];\n\n    const ratio = (value - range1[0]) / dist1; //range [0,1]\n    let norm = range2[0] + ratio * dist2;\n    return norm;\n  }\n\n  //2d plane coordinates => unit circle r=1.\n  // note: not a map but simply limits coordinates outside of radius to on circle.\n  __normalizeRect2Circ(coords, radius = 1) {\n    let [x, y] = coords;\n    let x_sign = x > 0 ? 1 : -1;\n    let y_sign = y > 0 ? 1 : -1;\n\n    if (Math.sqrt(x ** 2 + y ** 2) <= radius) {\n      return [x, y];\n    }\n\n    const theta = Math.atan(y / x);\n    const y_b = y_sign * Math.abs(radius * Math.sin(theta));\n    const x_b = x_sign * Math.abs(radius * Math.cos(theta));\n    return [x_b, y_b];\n  }\n\n  // TODO rename/mvoe to blaze/mesh class\n  // returns \"up\", \"down\",\"left\",\"right\"\n  __getDirection(coords, central_bounding) {\n    const [x, y] = coords;\n\n    let direction;\n    // get bounding config\n    let bounding_x = central_bounding.x;\n    let bounding_y = central_bounding.y;\n    let [x_min, x_max] = bounding_x;\n    let [y_min, y_max] = bounding_y;\n\n    // estimate direction\n    if (x <= x_max && x >= x_min && y <= y_max && y >= y_min) {\n      direction = 'center';\n    } else if (x < x_max && x > x_min) {\n      if (y > y_max) {\n        direction = 'up';\n      } else if (y < y_min) {\n        direction = 'down';\n      }\n    } else if (y < y_max && y > y_min) {\n      if (x > x_max) {\n        direction = 'right';\n      } else if (x < x_min) {\n        direction = 'left';\n      }\n    }\n    return direction;\n  }\n\n  //TODO is this needed in this form? // maybe it is good for stuff with 2d bounding..?\n  // where are the scaling operations happening?\n  __getVectorNormalized(coords, outer_bounding, scale = 1) {\n    const [x, y] = coords;\n\n    // get bounding config\n    let bounding_x = outer_bounding.x.map((v) => v * scale); //z axis normalization;\n    let bounding_y = outer_bounding.y.map((v) => v * scale); //z axis normalization;\n    let [x_min, x_max] = bounding_x;\n    let [y_min, y_max] = bounding_y;\n\n    let x_normalized = this.__normalizeInRange(x, [x_min, x_max], [-1, 1]); // range normalization\n    let y_normalized = this.__normalizeInRange(y, [y_min, y_max], [-1, 1]);\n\n    return [x_normalized, y_normalized];\n  }\n}\n","import * as blazeface from '@tensorflow-models/blazeface';\n// import * as tf from '@tensorflow/tfjs';\nimport { FACE_SCALE } from '../../constants';\nimport { distanceCoordinates } from '../../helpers/geometry';\n\nimport './__VectorDetector';\nimport VectorDetector from './__VectorDetector';\n\nexport default class NVDBlaze extends VectorDetector {\n  constructor(config) {\n    super(config);\n    // super(config);\n    // this.model = model;\n  }\n\n  async load() {\n    this.model = await blazeface.load({ maxFaces: 1 });\n  }\n\n  async detect(video) {\n    // Get predictions from model\n    let predictions = await this.model.estimateFaces(video);\n    if (!predictions.length) {\n      return false;\n    }\n\n    // Extract relevant data\n    let data = this.__getPredictionData(predictions[0]);\n    const { scale } = data;\n    const { tip: nose } = data.nose;\n    const { center } = data.face;\n\n    let vectors = this.__getNosePointVectors(nose, center, scale);\n    let config = this.config;\n\n    // note estimateFaces complete *predictions* are also included here (DO NOT call it again!)\n    return { vectors, predictions: predictions[0] };\n  }\n\n  __getPredictionData(prediction) {\n    const eye_l = prediction.landmarks[0];\n    const eye_r = prediction.landmarks[1];\n    const nose = prediction.landmarks[2];\n    const eyeDist = distanceCoordinates(eye_l, eye_r);\n    const scale = eyeDist / FACE_SCALE;\n    const topLeft = prediction.topLeft;\n    const bottomRight = prediction.bottomRight;\n    const width = bottomRight[0] - topLeft[0];\n    const height = bottomRight[1] - topLeft[1];\n    const center = [topLeft[0] + width / 2, topLeft[1] + height / 2];\n\n    // return { topLeft, bottomRight, width, height, center, nose };\n\n    return {\n      scale,\n      face: { topLeft, bottomRight, width, height, center },\n\n      nose: {\n        tip: nose,\n      },\n    };\n  }\n}\n","const FACE_SCALE = 85;\nconst HAND_SCALE = 1; // currently unused?\nexport { FACE_SCALE, HAND_SCALE };\n","\n\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\n\n\nimport { distanceCoordinates } from '../../helpers/geometry';\nimport { FACE_SCALE } from '../../constants';\n\nimport './__VectorDetector';\nimport VectorDetector from './__VectorDetector';\n\nexport default class NVDMesh extends VectorDetector {\n  constructor(config) {\n    super(config);\n    // super(config);\n    // this.model = model;\n  }\n\n  async load() {\n    this.model = await faceLandmarksDetection.load(\n      faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,\n      { maxFaces: 1, shouldLoadIrisModel: false }\n    );\n  }\n\n  async detect(video) {\n    // Get predictions from model\n    let predictions = await this.model.estimateFaces({\n      input: video,\n      predictIrises: false,\n    });\n\n    if (!predictions.length) {\n      return false;\n    }\n\n    // Extract relevant data\n    let data = this.__getPredictionData(predictions[0]);\n    const { scale } = data;\n    const { center } = data.face;\n    const {\n      rightEyeLower1,\n      rightEyeUpper1,\n      leftEyeLower1,\n      leftEyeUpper1,\n    } = data.eyes;\n    const { lipsLowerInner, lipsUpperInner } = data.mouth;\n    const { tip } = data.nose;\n\n    // Calculate vectors\n    let noseVectors = this.__getNosePointVectors(tip, center, scale);\n    let mouthVector = this.__getMouthOpenVector(\n      lipsLowerInner,\n      lipsUpperInner,\n      scale\n    );\n    let eyeVectors = this.__getEyesClosedVectors(\n      rightEyeLower1,\n      rightEyeUpper1,\n      leftEyeLower1,\n      leftEyeUpper1,\n      scale\n    );\n\n    let vectors = {\n      ...noseVectors,\n      ...mouthVector,\n      ...eyeVectors,\n    };\n    // let config = this.config;\n\n    // Return info\n\n    // return int_vectors = vectors for first loop\n    return { int_vectors: vectors, vectors, data, predictions: predictions[0] }; // not 'raw' data (predictions also included) data is kinda a shit dupe of this? (but useful for us here/.)\n  }\n\n  // Extract useful data from raw data\n  __getPredictionData(prediction) {\n    //face\n    const { topLeft, bottomRight } = prediction.boundingBox;\n    const width = bottomRight[0] - topLeft[0];\n    const height = bottomRight[1] - topLeft[1];\n    const center = [topLeft[0] + width / 2, topLeft[1] + height / 2];\n\n    let {\n      lipsLowerInner,\n      lipsUpperInner,\n      rightEyeLower1,\n      rightEyeUpper1,\n      leftEyeLower1,\n      leftEyeUpper1,\n    } = prediction.annotations;\n\n    lipsLowerInner = lipsLowerInner[5];\n    lipsUpperInner = lipsUpperInner[5];\n    rightEyeLower1 = rightEyeLower1[4];\n    rightEyeUpper1 = rightEyeUpper1[4];\n    leftEyeLower1 = leftEyeLower1[4];\n    leftEyeUpper1 = leftEyeUpper1[4];\n\n    const eyeDist = distanceCoordinates(rightEyeLower1, leftEyeLower1);\n    const noseTip = prediction.scaledMesh[4];\n    const scale = eyeDist / FACE_SCALE;\n    return {\n      scale,\n      face: { topLeft, bottomRight, width, height, center },\n      eyes: {\n        rightEyeLower1,\n        rightEyeUpper1,\n        leftEyeLower1,\n        leftEyeUpper1,\n        eyeDist,\n      },\n      nose: {\n        tip: noseTip,\n      },\n      mouth: { lipsLowerInner, lipsUpperInner },\n    };\n    // return {\n    //   topLeft,\n    //   bottomRight,\n    //   width,\n    //   height,\n    //   center,\n    //   nose,\n    //   lipsLowerInner,\n    //   lipsUpperInner,\n    //   rightEyeLower1,\n    //   rightEyeUpper1,\n    //   leftEyeLower1,\n    //   leftEyeUpper1,\n    //   eyeDist,\n    //   scale,\n    // };\n  }\n\n  __getMouthOpenVector(lipUpper, lipLower, scale) {\n    let distance = distanceCoordinates(lipUpper, lipLower) / scale; // z normalized\n    let mouth_bounding = this.config.mouth_bounding;\n    const normalized_mouth = this.__normalizeInRange(distance, mouth_bounding);\n\n    return { normalized_mouth };\n  }\n  //output is a bit shit but that the model not the fn\n  __getEyesClosedVectors(\n    rightEyeLower1,\n    rightEyeUpper1,\n    leftEyeLower1,\n    leftEyeUpper1,\n    scale\n  ) {\n    let distance_r =\n      distanceCoordinates(rightEyeLower1, rightEyeUpper1) / scale; //distance normalized for z-dist\n    let eye_bounding = this.config.eye_bounding;\n    const normalized_eye_r = this.__normalizeInRange(distance_r, eye_bounding);\n    let distance_l = distanceCoordinates(leftEyeLower1, leftEyeUpper1) / scale; //distance normalized for z-dist\n\n    const normalized_eye_l = this.__normalizeInRange(distance_l, eye_bounding);\n\n    return { normalized_eye_r, normalized_eye_l };\n  }\n}\n","import * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\n\nimport './__VectorDetector';\nimport VectorDetector from './__VectorDetector';\n\n// TODO extends Mesh\n\nexport default class IVDMesh extends VectorDetector {\n  constructor(config) {\n    super( config);\n  }\n\n  async load() {\n    this.model = await faceLandmarksDetection.load(\n      faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,\n      { maxFaces: 1, shouldLoadIrisModel: true }\n    );\n  }\n\n  async detect(video) {\n    // Get predictions from model\n    let predictions = await this.model.estimateFaces({\n      input: video,\n      predictIrises: true,\n    });\n    if (!predictions.length) {\n      return false;\n    }\n\n    // Extract relevant data\n    const { nose, center } = this.__getPredictionData(predictions[0]);\n\n    let vectors = this.__getNosePointVectors(nose, center);\n    let config = this.config;\n\n    // note estimateFaces complete *predictions* are also included here (DO NOT call it again!)\n    return { vectors, predictions: predictions[0] };\n  }\n\n  __getPredictionData(prediction) {\n    let annots = prediction.annotations;\n\n    let {\n      leftEyeIris,\n      leftEyeLower0,\n      leftEyeLower1,\n      leftEyeLower2,\n      leftEyeLower3,\n      leftEyeUpper0,\n      leftEyeUpper1,\n      leftEyeUpper2,\n    } = annots;\n\n    let pts = [\n      ...leftEyeLower0,\n      // ...leftEyeLower1,\n      // ...leftEyeLower2,\n      // ...leftEyeLower3,\n      ...leftEyeUpper0,\n      // ...leftEyeUpper1,\n      // ...leftEyeUpper2,\n    ];\n    //find average (central point)\n    let l = pts.length;\n    let c = pts\n      .reduce(\n        (acc, curr, i, a) => {\n          let [x, y] = acc;\n          let [xc, yc] = curr;\n          return [x + xc, y + yc];\n        },\n        [0, 0]\n      )\n      .map((v) => v / l);\n\n    // const topLeft = prediction.topLeft;\n    // const bottomRight = prediction.bottomRight;\n    // const width = bottomRight[0] - topLeft[0];\n    // const height = bottomRight[1] - topLeft[1];\n    // const center = [topLeft[0] + width / 2, topLeft[1] + height / 2];\n\n    // const nose = prediction.landmarks[2];\n\n    const nose = leftEyeIris[0]; //not nose..\n    const center = c;\n\n    return { center, nose };\n  }\n}\n","import * as handpose from '@tensorflow-models/handpose';\nimport {\n  distanceCoordinates,\n  angleCoordinatesXY,\n  averageCoordinate,\n} from '../../helpers/geometry';\nimport { HAND_SCALE } from '../../constants';\n\nimport './__VectorDetector';\nimport VectorDetector from './__VectorDetector';\n\nexport default class VDHandpose extends VectorDetector {\n  constructor(config) {\n    super(config);\n    // super(config);\n    // this.model = model;\n  }\n\n  async load() {\n    this.model = await handpose.load();\n  }\n\n  async detect(video) {\n    // Get predictions from model\n    const predictions = await this.model.estimateHands(\n      document.querySelector('video')\n    );\n\n    if (!predictions.length) {\n      return false;\n    }\n\n    // Extract relevant data\n    let data = this.__getPredictionData(predictions[0]);\n\n    // const { center ,width, height} = data;\n    let { indexFinger, middleFinger, palmBase, pink, ringFinger, thumb } = data;\n    let finger1Tip = indexFinger[3];\n    let thumbTip = thumb[3];\n\n    // Calculate vectors\n\n    let pinchPos1 = this.__getPinchPos(thumbTip, finger1Tip, 1);\n\n    let pinch1 = this.__getPinchVector(\n      thumbTip,\n      finger1Tip,\n      this.config.pinch1_bounding,\n      1\n    );\n    //assuming right hand for direction of rotation though no so important\n    let rotation1 = this.__getRotation(\n      thumbTip,\n      finger1Tip,\n      this.config.rotation1_bounding,\n      1\n    );\n\n    let vectors = { pinch1, rotation1, pinchPos1 };\n    // let config = this.config;\n\n    // Return info\n\n    // return int_vectors = vectors for first loop\n    return { int_vectors: vectors, vectors, data, predictions: predictions[0] }; // not 'raw' data (predictions also included) data is kinda a shit dupe of this? (but useful for us here/.)\n  }\n\n  // Extract useful data from raw data\n  __getPredictionData(prediction) {\n    //face\n    const { topLeft, bottomRight } = prediction.boundingBox;\n    const width = bottomRight[0] - topLeft[0];\n    const height = bottomRight[1] - topLeft[1];\n    const center = [topLeft[0] + width / 2, topLeft[1] + height / 2];\n\n    // const scale = eyeDist / FACE_SCALE;\n    return { topLeft, width, height, center, ...prediction.annotations };\n  }\n  // should be a more general fn\n\n  // normalized [0,1]\n  __getPinchPos(thumbTip, finger1Tip, pinchBounding, scale) {\n    const dims = [640, 480];\n\n    let p = averageCoordinate([thumbTip, finger1Tip]);\n    let norm = [p[0] / dims[0], p[1] / dims[1]];\n    return norm;\n  }\n\n  __getPinchVector(thumbTip, finger1Tip, pinchBounding, scale) {\n    let distance = distanceCoordinates(thumbTip, finger1Tip) / scale; // z normalized\n    const normalizedPinch = this.__normalizeInRange(distance, pinchBounding);\n    return normalizedPinch;\n  }\n\n  __getRotation(thumbTip, finger1Tip, rotationBounding, scale) {\n    let angle;\n    let distance = distanceCoordinates(thumbTip, finger1Tip) / scale; // z normalized\n    if (distance < rotationBounding[0] || distance > rotationBounding[1]) {\n      return null;\n    }\n    angle = angleCoordinatesXY(thumbTip, finger1Tip);\n\n    return angle;\n  }\n\n  //output is a bit shit but that the model not the fn\n}\n","// TESTER FILE - FN AT BOTTOM\n\nconsole.clear();\n\nlet o1 = {\n  val: [0, 1],\n  val2: [0.4, 0.2],\n  val3: [\n    [0.4, 0.2],\n    [0.4, 0.2],\n    [0.4, 0.2],\n  ],\n  val4: 3,\n  val5: 'string',\n  val6: {\n    val: [1, 0, 2],\n  },\n};\n\nlet o2 = {\n  val: [0, 0.8],\n  val2: [0.1, 0.1],\n  val3: [\n    [0.4, 0.3],\n    [0.5, 0.2],\n    [0.4, 0.2],\n  ],\n  val4: 4,\n  val5: 'straang',\n\n  val6: {\n    val: [1, 0, 1],\n  },\n};\n\nfunction isObject(item) {\n  return item && typeof item === 'object' && !Array.isArray(item);\n}\nfunction mapDeep(mapper, mapperArgs, target, source) {\n  if (isObject(target) && isObject(source)) {\n    for (const key in source) {\n      if (isObject(source[key])) {\n        if (!target[key]) Object.assign(target, { [key]: {} });\n        mapDeep(target[key], source[key]);\n      } else {\n        Object.assign(target, {\n          [key]: mapper(mapperArgs, key, target[key], source[key]),\n        });\n      }\n    }\n  }\n\n  return target;\n}\n\n// slightly confusing way around o1, o2 but I might be dumb\n// let o3 = mapDeep(mapper, o1, o2);\n// console.log(o3);\n\n// this is what user will enter in config\n//optional key arg for picking out specific keys if wanted (otherwise just use array length)\nfunction mapper(val1, val2, key) {\n  // console.log(key);\n  if (Array.isArray(val1)) {\n    if (val1.length === 2) {\n      return stepToward2D(val1, val2, 0.1);\n    }\n    // if /...\n    // handle long array of arrays,\n    // 3d array\n    else return val2; // or 1?\n  }\n  if (typeof val1 === 'number') {\n    return stepToward1D(val1, val2, 0.1);\n  }\n  return val2; // if none of the above are satisfied\n}\n\nfunction stepToward2D(prevPos, actualPos, stepSize = 0.1) {\n  let x, y;\n  let [x1, y1] = [...prevPos];\n  let [x2, y2] = [...actualPos];\n\n  let d_x = x2 - x1;\n  let d_y = y2 - y1;\n\n  x = x1 + d_x * stepSize;\n  y = y1 + d_y * stepSize;\n  return [x, y];\n}\n\nfunction stepToward1D(prevVal, actualVal, stepSize = 0.1) {\n  let d_x = actualVal - prevVal;\n\n  return prevVal + d_x * stepSize;\n}\n\nexport default mapDeep;\n","import { stepToward1D, stepToward2D } from './geometry';\nimport mapDeep from './mapDeep';\n\n// returns a stepToward function\n//optional  params for setting the individual function or step value for keys of prediction (i.e. landmarks, normalized_circle etc.)\nexport default function tfStepTowardFactory(mapperArgs) {\n  return (prevPredictions, currentPredictions) => {\n    let int_vectors;\n    let int_predictions;\n    if (prevPredictions.int_vectors) {\n      int_vectors = mapDeep(\n        stepMapper,\n        mapperArgs,\n        prevPredictions.int_vectors,\n        currentPredictions.vectors\n      );\n    } else {\n      // handle first loop where no int values exist\n      int_vectors = currentPredictions.vectors;\n    }\n    if (prevPredictions.int_predictions) {\n      int_predictions = mapDeep(\n        stepMapper,\n        mapperArgs,\n        prevPredictions.int_predictions,\n        currentPredictions.predictions\n      );\n    } else {\n      // console.log(\"first loop\")\n      int_predictions = currentPredictions.predictions;\n    }\n\n    return {\n      ...currentPredictions,\n      int_vectors,\n      int_predictions,\n    };\n  };\n}\n\nfunction stepMapper(mapperArgs, key, val1, val2) {\n  let step = 0.1;\n  let stepperFunction;\n  if (key in mapperArgs) {\n    let val = mapperArgs[key];\n    if (!val) {\n      //set to false (i.e dont interpolate)\n      return val2;\n    }\n    if (val.step) {\n      step = val.step;\n    }\n    if (val.stepperFunction) {\n      //todo: also accept a string and a lookup for a function here (i.e. different stepperfns to pick from)\n      stepperFunction = val.stepperFunction;\n      // setting to false stops interpolation [note: for performace it should be set to false by default...]\n    }\n  }\n  // console.log(key);\n  if (Array.isArray(val1)) {\n    if (Array.isArray(val1[0])) {\n      // array of arrays\n      return val1.map((v1, idx) => stepMapper(mapperArgs, key, v1, val2[idx]));\n    }\n    if (val1.length === 2) {\n      if (stepperFunction) {\n        return stepperFunction(val1, val2, step);\n      } else {\n        return stepToward2D(val1, val2, step);\n      }\n    }\n    if (val1.length === 3) {\n      if (stepperFunction) {\n        return stepperFunction(val1, val2, step);\n      } else {\n        return stepToward2D(val1, val2, step); // TO DO 3D VERSION or just make a generic stepToward fn for all dims..\n      }\n    }\n  }\n  if (typeof val1 === 'number') {\n    if (stepperFunction) {\n      return stepperFunction(val1, val2, step);\n    } else {\n      return stepToward1D(val1, val2, step);\n    }\n  }\n  return val2; // if none of the above are satisfied\n}\n","// Presets for FaceDetector class\n\nimport {\n  stepToward,\n  stepTowardLinear,\n  stepToward1D,\n  stepToward2D,\n} from './helpers/geometry';\nimport tfStepTowardFactory from './helpers/tfStepTowardFactory';\n\n// measured in pixels where eyes are FACE_SCALE (constant) distance apart\n// scaled for z distance in calculations\n// TO DO: set as [0,1] - width/height of full capture\nconst defaultsMULTI = {\n  blaze: {\n    detector: {\n      central_bounding: { x: [-20, 20], y: [-20, 15] },\n      outer_bounding: { x: [-50, 50], y: [-35, 15] },\n    },\n    interpolator: {\n      predictions: true,\n      vectors: true,\n\n      fps: 1, // zero is max\n      sensitivity: 0.07,\n\n      mapperArgs: {\n        // landmarks: {\n        //   step: 0.1,\n        //   stepperFunction: stepToward2D,\n        // },\n        probability: false,\n      },\n      get stepperFactory() {\n        return tfStepTowardFactory;\n      },\n    },\n  },\n  mesh: {\n    detector: {\n      central_bounding: { x: [-20, 20], y: [-20, 15] },\n      outer_bounding: { x: [-50, 50], y: [-35, 15] },\n      mouth_bounding: [0, 25],\n      eye_bounding: [20, 32],\n    },\n    interpolator: {\n      fps: 0, // zero is gives a max fps\n      sensitivity: 0.07,\n      mapperArgs: {\n        probability: false,\n      },\n\n      get stepperFactory() {\n        return tfStepTowardFactory;\n      },\n    },\n  },\n  handpose: {\n    detector: {\n      central_bounding: { x: [-20, 20], y: [-20, 15] },\n      outer_bounding: { x: [-50, 50], y: [-35, 15] },\n      pinch1_bounding: [50, 150],\n      rotation1_bounding: [100, 200], //rotation not registered outside of this dist betw fingers\n\n      pinch2_bounding: [50, 150],\n      pinch3_bounding: [50, 150],\n      pinch4_bounding: [50, 150],\n    },\n    interpolator: {\n      fps: 0, // zero is max\n      sensitivity: 0.25,\n      mapperArgs: {\n        probability: false,\n      },\n      get stepperFactory() {\n        return tfStepTowardFactory;\n      },\n    },\n  },\n  // iris: {\n  //   detector: {\n  //     central_bounding: { x: [-20, 20], y: [-20, 15] },\n  //     outer_bounding: { x: [-50, 50], y: [-35, 15] },\n  //     mouth_bounding: [0, 10],\n  //     eye_bounding: [25, 32],\n  //   },\n  //   interpolator: {\n  //     fps: 0, // zero is max\n  //     sensitivity: 0.07,\n  //     stepToward: stepTowardDetector,\n  //   },\n  // },\n};\n\nexport { defaultsMULTI };\n\n// TODO: a method that has [\"vector-normalized-cicle\",\"vector-normalized-square\"] as argument instead of this object madness\n// SEE MAPDEEP\nfunction stepTowardDetector(prevPredictions, currentPredictions, sensitivity) {\n  // TODO handle first loop where int_vectors (for example might not exist)\n  // hand that here??? or just continue to use original vector object as below/returned by detect fn in indiv detectors\n  // (where is it cleanest? probably not here)\n  const { vectors } = currentPredictions;\n  const {\n    nose_normalized_circle,\n    nose_normalized_square,\n    normalized_mouth,\n  } = vectors;\n\n  // handel no int_vectors here (i.e. create object)\n\n  return {\n    ...currentPredictions,\n    // ...vectors,\n    // mapdeep here on int_vectors, int_predictions...\n    int_vectors: {\n      nose_normalized_circle: stepToward(\n        prevPredictions.int_vectors?.nose_normalized_circle ||\n          prevPredictions.vectors.nose_normalized_circle, //first iteration this object does not exist\n        nose_normalized_circle,\n        sensitivity // can just set value here - doesnt have to be same sensitivity val everywhere\n      ),\n      nose_normalized_square: stepToward(\n        prevPredictions.int_vectors?.nose_normalized_square ||\n          prevPredictions.vectors.nose_normalized_square,\n        nose_normalized_square,\n        sensitivity\n      ),\n      normalized_mouth: stepTowardLinear(\n        prevPredictions.int_vectors?.normalized_mouth ||\n          prevPredictions.vectors.normalized_mouth,\n\n        normalized_mouth,\n        sensitivity\n      ),\n    },\n  };\n}\n\nfunction handposeStepTowardDetector(\n  prevPredictions,\n  currentPredictions,\n  sensitivity\n) {\n  const { vectors } = currentPredictions;\n  const { pinch1, rotation1, pinchPos1 } = vectors;\n\n  return {\n    ...currentPredictions,\n    // ...vectors,\n    int_vectors: {\n      pinch1: stepTowardLinear(\n        prevPredictions.int_vectors?.pinch1 || prevPredictions.vectors.pinch1,\n        pinch1,\n        sensitivity\n      ),\n      pinchPos1: stepToward(\n        prevPredictions.int_vectors?.pinchPos1 ||\n          prevPredictions.vectors.pinchPos1,\n        pinchPos1,\n        sensitivity\n      ),\n      rotation1: stepTowardLinear(\n        prevPredictions.int_vectors?.rotation1 ||\n          prevPredictions.vectors.rotation1,\n        rotation1,\n        sensitivity\n      ),\n    },\n  };\n}\n","import * as tf from '@tensorflow/tfjs-core';\nimport '@tensorflow/tfjs-backend-webgl';\n// import * as tfjsWasm from '@tensorflow/tfjs-backend-wasm';\nimport '@tensorflow/tfjs-backend-cpu';\n// not using tf.setBackend ..\n\nimport InterpolatedDetector from './classes/InterpolatedDetector';\nimport VectorDetector from './classes/Detectors/__VectorDetector';\nimport NVDBlaze from './classes/Detectors/VDBlaze';\nimport NVDMesh from './classes/Detectors/VDMesh';\nimport IVDMesh from './classes/Detectors/VDIrisMesh';\nimport VDHandpose from './classes/Detectors/VDHandpose';\n// import { op } from '@tensorflow/tfjs';\n// import { defaults } from './defaults';\nimport { defaultsMULTI } from './defaultsMULTI';\nimport { mergeDeep } from './helpers/helpers';\n\n// MULTI - args: [{name: \"blaze\", config:{asdf}, \"mesh\"] ; args array contains either object (with configs) OR string (default configs)\n// config here! i.e.- new IVDMesh(configs)  - merge with defaults so that vectorDetector always has full config\n\nexport default function nosePoseMULTI(options = []) {\n  let detectors = {};\n  // {blaze: {detector: NVDDetector(class), config:{detector:{}, interpolator:{}}}, mesh: {detector: NVDDetector(class), config:{}}, etc }\n\n  options.forEach((option) => {\n    let d;\n    if (typeof option === 'string') {\n      d = getDetector(option, null);\n      let name = option;\n      detectors[name] = d;\n    } else {\n      let name = option.name;\n      d = getDetector(name, option.config);\n      detectors[name] = d;\n    }\n  });\n\n  let smoothDetector = new InterpolatedDetector(detectors);\n  return smoothDetector;\n}\n\n/**\n *\n * @param {name\n * } type string\n */\nfunction getDetector(name, config) {\n  let detector;\n  // add in configs that haven't been specified\n  let configMerged = mergeDeep({}, defaultsMULTI[name], config);\n\n  switch (name) {\n    case 'iris':\n      detector = new IVDMesh(configMerged.detector);\n      break;\n    case 'mesh':\n      detector = new NVDMesh(configMerged.detector);\n      break;\n    case 'blaze':\n      detector = new NVDBlaze(configMerged.detector);\n      break;\n    case 'handpose':\n      detector = new VDHandpose(configMerged.detector);\n      break;\n    default:\n      //none\n      // detector = new NVDBlaze(configMerged.detector);\n\n      break;\n  }\n  // add configs that are not supplied\n\n  // return detector object\n  return { detector, config: configMerged };\n}\n"],"names":["isObject","item","Array","isArray","mergeDeep","target","sources","length","source","shift","key","Object","assign","[object Object]","Interpolator","constructor","slowPromise","stepToward","fps","this","fast","slow","resolved","interpolate","val","__updateSlow","__updateFast","v","p1","p2","__timeoutPromise","Promise","all","resolve","reject","setTimeout","then","distanceCoordinates","c1","c2","Math","sqrt","Error","stepToward2D","prevPos","actualPos","stepSize","x","y","x1","y1","x2","y2","InterpolatedDetectorMULTI","detectors","loaded","animationFrameId","promises","values","forEach","d","push","detector","load","stepperFactory","mapperArgs","config","interpolator","interpolatorFunction","video","detect","console","log","configure","configs","keys","dd","__configureDetector","__configureInterpolator","detections","n","startDetection","loopers","looper","fn","requestAnimationFrame","stopDetection","cancelAnimationFrame","VectorDetector","model","__getNosePointVectors","nose","center","scale","outer_bounding","coords","direction_word","__getDirection","central_bounding","vector","nose_normalized_square","__getVectorNormalized","nose_normalized_circle","__normalizeRect2Circ","__normalizeInRange","value","range1","range2","radius","x_sign","y_sign","theta","atan","y_b","abs","sin","cos","direction","bounding_x","bounding_y","x_min","x_max","y_min","y_max","map","NVDBlaze","super","blazeface","maxFaces","predictions","estimateFaces","data","__getPredictionData","tip","face","vectors","prediction","landmarks","eyeDist","topLeft","bottomRight","width","height","NVDMesh","faceLandmarksDetection","mediapipeFacemesh","shouldLoadIrisModel","input","predictIrises","rightEyeLower1","rightEyeUpper1","leftEyeLower1","leftEyeUpper1","eyes","lipsLowerInner","lipsUpperInner","mouth","__getMouthOpenVector","__getEyesClosedVectors","int_vectors","boundingBox","annotations","scaledMesh","lipUpper","lipLower","distance","normalized_mouth","mouth_bounding","distance_r","eye_bounding","normalized_eye_r","distance_l","normalized_eye_l","IVDMesh","annots","leftEyeIris","leftEyeLower0","leftEyeUpper0","pts","l","reduce","acc","curr","i","a","xc","yc","VDHandpose","handpose","estimateHands","document","querySelector","indexFinger","thumb","finger1Tip","thumbTip","pinchPos1","__getPinchPos","pinch1","__getPinchVector","pinch1_bounding","rotation1","__getRotation","rotation1_bounding","pinchBounding","dims","p","array","z","zc","averageCoordinate","rotationBounding","angle","PI","angleCoordinatesXY","mapDeep","mapper","tfStepTowardFactory","prevPredictions","currentPredictions","int_predictions","stepMapper","val1","val2","stepperFunction","step","v1","idx","prevVal","actualVal","stepToward1D","clear","defaultsMULTI","blaze","sensitivity","probability","mesh","pinch2_bounding","pinch3_bounding","pinch4_bounding","nosePoseMULTI","options","option","getDetector","name","InterpolatedDetector","configMerged"],"mappings":"2SAKA,SAASA,EAASC,GAChB,OAAOA,GAAwB,iBAATA,IAAsBC,MAAMC,QAAQF,GAQ5D,SAASG,EAAUC,KAAWC,GAC5B,IAAKA,EAAQC,OAAQ,OAAOF,EAC5B,MAAMG,EAASF,EAAQG,QAEvB,GAAIT,EAASK,IAAWL,EAASQ,GAC/B,IAAK,MAAME,KAAOF,EACZR,EAASQ,EAAOE,KACbL,EAAOK,IAAMC,OAAOC,OAAOP,EAAQ,CAAEQ,CAACH,GAAM,KACjDN,EAAUC,EAAOK,GAAMF,EAAOE,KAE9BC,OAAOC,OAAOP,EAAQ,CAAEQ,CAACH,GAAMF,EAAOE,KAK5C,OAAON,EAAUC,KAAWC,SCvBTQ,EACnBC,YAAYC,EAAaC,EAAYC,GAAM,GACzCC,KAAKH,YAAcA,EACnBG,KAAKF,WAAaA,EAClBE,KAAKC,KAAO,KACZD,KAAKE,KAAO,KACZF,KAAKG,UAAW,EAChBH,KAAKD,IAAMA,EAGbK,YAAYC,GAGV,OAFAL,KAAKM,aAAaD,GAClBL,KAAKO,oBACON,KAEdM,eAIIP,KAAKC,KAHFD,KAAKC,KAGID,KAAKF,WAAWE,KAAKC,KAAMD,KAAKE,MAFhCF,KAAKE,KAKHR,mBAACW,GACjB,GAAKL,KAAKG,UAGNH,KAAKG,SAAU,CAEjB,IAAIK,EAEJ,GAHAR,KAAKG,UAAW,EAGZH,KAAKD,IAAK,CAOZ,MAAOU,EAAIC,GAAM,CAACV,KAAKH,YAAYQ,GAAML,KAAKW,oBAE9CH,SADcI,QAAQC,IAAI,CAACJ,EAAIC,KACzB,GACNV,KAAKG,UAAW,EAChBK,IAAMR,KAAKE,KAAOM,QAElBA,aAAeX,YAAYQ,GAC3BL,KAAKG,UAAW,EAChBK,IAAMR,KAAKE,KAAOM,IAMFd,yBAEpB,WAAWkB,QAAQ,CAACE,EAASC,KAC3BC,WAAWF,EAAS,IAAOd,KAAKD,OAC/BkB,KAAK,0NCvBZ,SAASC,EAAoBC,EAAIC,GAC/B,GAAkB,IAAdD,EAAG/B,OACL,OAAOiC,KAAKC,MAAMF,EAAG,GAAKD,EAAG,KAAO,GAAKC,EAAG,GAAKD,EAAG,KAAO,MACpC,IAAdA,EAAG/B,OACZ,OAAOiC,KAAKC,MACTF,EAAG,GAAKD,EAAG,KAAO,GAAKC,EAAG,GAAKD,EAAG,KAAO,GAAKC,EAAG,GAAKD,EAAG,KAAO,GAGnE,UAAUI,MAAM,iCAgBpB,SAASC,EAAaC,EAASC,EAAWC,EAAW,IACnD,IAAIC,EAAGC,GACFC,EAAIC,GAAM,IAAIN,IACdO,EAAIC,GAAM,IAAIP,GAOnB,OAFAE,EAAIE,GAHME,EAAKF,GAGAH,EACfE,EAAIE,GAHME,EAAKF,GAGAJ,EACR,CAACC,EAAGC,SC7DQK,EACnBtC,YAAYuC,GAEVnC,KAAKmC,UAAYA,EACjBnC,KAAKoC,QAAS,EACdpC,KAAKqC,iBAAmB,KAGhB3C,aACR,IAAI4C,EAAW,GACf9C,OAAO+C,OAAOvC,KAAKmC,WAAWK,QAASC,IAErCH,EAASI,KAAKD,EAAEE,SAASC,QAKzB,MAAMC,eAAEA,EAAFC,WAAkBA,EAAlB/C,IAA8BA,GAAQ0C,EAAEM,OAAOC,aAC/CC,EAAuBJ,EAAeC,GAE5CL,EAAEO,aAAe,IAAIrD,EAClBuD,GAAUT,EAAEE,SAASQ,OAAOD,GAC7BD,EACAlD,WAGUa,QAAQC,IAAIyB,GAC1Bc,QAAQC,IAAI,cACZrD,KAAKoC,QAAS,EAGhBkB,UAAUC,GACO/D,OAAOgE,KAAKD,GAClBf,QAASC,IAEhB,IAAIgB,EAAKzD,KAAKmC,UAAUM,GAEpBc,EAAQd,GAAGE,UACb3C,KAAK0D,oBAAoBH,EAAQd,GAAGE,SAAUc,GAG5CF,EAAQd,GAAGO,cACbhD,KAAK2D,wBAAwBJ,EAAQd,GAAGO,aAAcS,KAM5DN,OAAOD,GACL,IAAKlD,KAAKoC,OACR,MAAO,GAET,IAAIwB,EAAa,GACjBpE,OAAOgE,KAAKxD,KAAKmC,WAAWK,QAASqB,IACnCD,EAAWC,GAAK7D,KAAKmC,UAAU0B,GAAGb,aAAa5C,YAAY8C,KAI7D,IAAIK,EAAU,GAKd,OAJA/D,OAAOgE,KAAKxD,KAAKmC,WAAWK,QAASqB,IACnCN,EAAQM,GAAK7D,KAAKmC,UAAU0B,GAAGd,SAG1B,CAAEa,WAAAA,EAAYL,QAAAA,GAIvBO,eAAeZ,EAAOa,EAAU,IAC9B,MAAMC,EAAS,KACb,IAAIvB,EAAIzC,KAAKmD,OAAOD,GAEhBa,EAAQ3E,QACV2E,EAAQvB,QAASyB,GAAOA,EAAGxB,IAE7BzC,KAAKqC,iBAAmB6B,sBAAsBF,IAEhDA,IAGFG,gBACEC,qBAAqBpE,KAAKqC,kBAE5BqB,oBAAoBX,EAAQJ,EAAW,IACrCnD,OAAOC,OAAOkD,EAASI,OAAOJ,SAAUI,GACxCJ,EAASA,SAASW,UAAUP,GAI9BY,wBAAwBZ,EAAQJ,EAAW,IACzC1D,EAAU0D,EAASI,OAAOC,aAAcD,GAExC,MAAMF,eAAEA,EAAFC,WAAkBA,EAAlB/C,IAA8BA,GAAQ4C,EAASI,OAAOC,aACtDC,EAAuBJ,EAAeC,GAE5CH,EAASK,aAAe,IAAIrD,EACzBuD,GAAUP,EAASA,SAASQ,OAAOD,GACpCD,EACAlD,UC1GesE,EACnBzE,YAAYmD,GACV/C,KAAKsE,MAAQ,KACbtE,KAAK+C,OAASA,EAKhBO,UAAUP,GACRvD,OAAOC,OAAOO,KAAK+C,OAAQA,GAK7BwB,sBAAsBC,EAAMC,EAAQC,EAAQ,GAC1C,IACIC,EAAiB3E,KAAK+C,OAAO4B,eAEjC,MAAM/C,EAAI6C,EAAO,GAAKD,EAAK,GACrB3C,EAAI4C,EAAO,GAAKD,EAAK,GAC3B,IAAII,EAAS,CAAChD,EAAGC,GAMjB,MAAMgD,EAAiB7E,KAAK8E,eAAeF,EAXpB5E,KAAK+C,OAAOgC,kBAY7BC,EAAS,CAACpD,EAAGC,GAGboD,EAAyBjF,KAAKkF,sBAClCN,EACAD,EACAD,GAMF,MAAO,CACLG,eAAAA,EACAG,OAAAA,EACAC,uBAAAA,EACAE,uBAR6BnF,KAAKoF,qBAClCH,IAWJI,mBAAmBC,EAAOC,EAAQC,EAAS,CAAC,EAAG,IAC7C,OAAIF,EAAQC,EAAO,GACVC,EAAO,GAEZF,EAAQC,EAAO,GACVC,EAAO,GAMLA,EAAO,IADHF,EAAQC,EAAO,KAHlBA,EAAO,GAAKA,EAAO,KACnBC,EAAO,GAAKA,EAAO,IASjCJ,qBAAqBR,EAAQa,EAAS,GACpC,IAAK7D,EAAGC,GAAK+C,EACTc,EAAS9D,EAAI,EAAI,GAAK,EACtB+D,EAAS9D,EAAI,EAAI,GAAK,EAE1B,GAAIR,KAAKC,KAAKM,GAAK,EAAIC,GAAK,IAAM4D,EAChC,MAAO,CAAC7D,EAAGC,GAGb,MAAM+D,EAAQvE,KAAKwE,KAAKhE,EAAID,GACtBkE,EAAMH,EAAStE,KAAK0E,IAAIN,EAASpE,KAAK2E,IAAIJ,IAEhD,MAAO,CADKF,EAASrE,KAAK0E,IAAIN,EAASpE,KAAK4E,IAAIL,IACnCE,GAKfhB,eAAeF,EAAQG,GACrB,MAAOnD,EAAGC,GAAK+C,EAEf,IAAIsB,EAEAC,EAAapB,EAAiBnD,EAC9BwE,EAAarB,EAAiBlD,GAC7BwE,EAAOC,GAASH,GAChBI,EAAOC,GAASJ,EAkBrB,OAfIxE,GAAK0E,GAAS1E,GAAKyE,GAASxE,GAAK2E,GAAS3E,GAAK0E,EACjDL,EAAY,SACHtE,EAAI0E,GAAS1E,EAAIyE,EACtBxE,EAAI2E,EACNN,EAAY,KACHrE,EAAI0E,IACbL,EAAY,QAELrE,EAAI2E,GAAS3E,EAAI0E,IACtB3E,EAAI0E,EACNJ,EAAY,QACHtE,EAAIyE,IACbH,EAAY,SAGTA,EAKThB,sBAAsBN,EAAQD,EAAgBD,EAAQ,GACpD,MAAO9C,EAAGC,GAAK+C,EAGf,IAAIuB,EAAaxB,EAAe/C,EAAE6E,IAAKjG,GAAMA,EAAIkE,GAC7C0B,EAAazB,EAAe9C,EAAE4E,IAAKjG,GAAMA,EAAIkE,IAC5C2B,EAAOC,GAASH,GAChBI,EAAOC,GAASJ,EAKrB,MAAO,CAHYpG,KAAKqF,mBAAmBzD,EAAG,CAACyE,EAAOC,GAAQ,EAAE,EAAG,IAChDtG,KAAKqF,mBAAmBxD,EAAG,CAAC0E,EAAOC,GAAQ,EAAE,EAAG,YCpHlDE,UAAiBrC,EACpCzE,YAAYmD,GACV4D,MAAM5D,GAKErD,aACRM,KAAKsE,YAAcsC,EAAe,CAAEC,SAAU,IAGpCnH,aAACwD,GAEX,IAAI4D,aAAyBxC,MAAMyC,cAAc7D,GACjD,IAAK4D,EAAY1H,OACf,SAIF,IAAI4H,EAAOhH,KAAKiH,oBAAoBH,EAAY,IAChD,MAAMpC,MAAEA,GAAUsC,GACVE,IAAK1C,GAASwC,EAAKxC,MACrBC,OAAEA,GAAWuC,EAAKG,KAMxB,MAAO,CAAEC,QAJKpH,KAAKuE,sBAAsBC,EAAMC,EAAQC,GAIrCoC,YAAaA,EAAY,IAG7CG,oBAAoBI,GAClB,MAEM7C,EAAO6C,EAAWC,UAAU,GAC5BC,EAAUrG,EAHFmG,EAAWC,UAAU,GACrBD,EAAWC,UAAU,IAI7BE,EAAUH,EAAWG,QACrBC,EAAcJ,EAAWI,YACzBC,EAAQD,EAAY,GAAKD,EAAQ,GACjCG,EAASF,EAAY,GAAKD,EAAQ,GAKxC,MAAO,CACL9C,MAVY6C,EC5CC,GDuDbJ,KAAM,CAAEK,QAAAA,EAASC,YAAAA,EAAaC,MAAAA,EAAOC,OAAAA,EAAQlD,OANhC,CAAC+C,EAAQ,GAAKE,EAAQ,EAAGF,EAAQ,GAAKG,EAAS,IAQ5DnD,KAAM,CACJ0C,IAAK1C,WE/CQoD,UAAgBvD,EACnCzE,YAAYmD,GACV4D,MAAM5D,GAKErD,aACRM,KAAKsE,YAAcuD,EACjBA,EAAyCC,kBACzC,CAAEjB,SAAU,EAAGkB,qBAAqB,IAI5BrI,aAACwD,GAEX,IAAI4D,aAAyBxC,MAAMyC,cAAc,CAC/CiB,MAAO9E,EACP+E,eAAe,IAGjB,IAAKnB,EAAY1H,OACf,SAIF,IAAI4H,EAAOhH,KAAKiH,oBAAoBH,EAAY,IAChD,MAAMpC,MAAEA,GAAUsC,GACZvC,OAAEA,GAAWuC,EAAKG,MAClBe,eACJA,EADIC,eAEJA,EAFIC,cAGJA,EAHIC,cAIJA,GACErB,EAAKsB,MACHC,eAAEA,EAAFC,eAAkBA,GAAmBxB,EAAKyB,OAC1CvB,IAAEA,GAAQF,EAAKxC,KAGrB,IAcI4C,OAdcpH,KAAKuE,sBAAsB2C,EAAKzC,EAAQC,GACxC1E,KAAK0I,qBACrBH,EACAC,EACA9D,GAEe1E,KAAK2I,uBACpBT,EACAC,EACAC,EACAC,EACA3D,IAaF,MAAO,CAAEkE,YAAaxB,EAASA,QAAAA,EAASJ,KAAAA,EAAMF,YAAaA,EAAY,IAIzEG,oBAAoBI,GAElB,MAAMG,QAAEA,EAAFC,YAAWA,GAAgBJ,EAAWwB,YACtCnB,EAAQD,EAAY,GAAKD,EAAQ,GACjCG,EAASF,EAAY,GAAKD,EAAQ,GAClC/C,EAAS,CAAC+C,EAAQ,GAAKE,EAAQ,EAAGF,EAAQ,GAAKG,EAAS,GAE9D,IAAIY,eACFA,EADEC,eAEFA,EAFEN,eAGFA,EAHEC,eAIFA,EAJEC,cAKFA,EALEC,cAMFA,GACEhB,EAAWyB,YAEfP,EAAiBA,EAAe,GAChCC,EAAiBA,EAAe,GAChCN,EAAiBA,EAAe,GAChCC,EAAiBA,EAAe,GAChCC,EAAgBA,EAAc,GAC9BC,EAAgBA,EAAc,GAE9B,MAAMd,EAAUrG,EAAoBgH,EAAgBE,GAGpD,MAAO,CACL1D,MAFY6C,EDvGC,GC0GbJ,KAAM,CAAEK,QAAAA,EAASC,YAAAA,EAAaC,MAAAA,EAAOC,OAAAA,EAAQlD,OAAAA,GAC7C6D,KAAM,CACJJ,eAAAA,EACAC,eAAAA,EACAC,cAAAA,EACAC,cAAAA,EACAd,QAAAA,GAEF/C,KAAM,CACJ0C,IAbYG,EAAW0B,WAAW,IAepCN,MAAO,CAAEF,eAAAA,EAAgBC,eAAAA,IAoB7BE,qBAAqBM,EAAUC,EAAUvE,GACvC,IAAIwE,EAAWhI,EAAoB8H,EAAUC,GAAYvE,EAIzD,MAAO,CAAEyE,iBAFgBnJ,KAAKqF,mBAAmB6D,EAD5BlJ,KAAK+C,OAAOqG,iBAMnCT,uBACET,EACAC,EACAC,EACAC,EACA3D,GAEA,IAAI2E,EACFnI,EAAoBgH,EAAgBC,GAAkBzD,EACpD4E,EAAetJ,KAAK+C,OAAOuG,aAC/B,MAAMC,EAAmBvJ,KAAKqF,mBAAmBgE,EAAYC,GAC7D,IAAIE,EAAatI,EAAoBkH,EAAeC,GAAiB3D,EAIrE,MAAO,CAAE6E,iBAAAA,EAAkBE,iBAFFzJ,KAAKqF,mBAAmBmE,EAAYF,WCvJ5CI,UAAgBrF,EACnCzE,YAAYmD,GACV4D,MAAO5D,GAGCrD,aACRM,KAAKsE,YAAcuD,EACjBA,EAAyCC,kBACzC,CAAEjB,SAAU,EAAGkB,qBAAqB,IAI5BrI,aAACwD,GAEX,IAAI4D,aAAyBxC,MAAMyC,cAAc,CAC/CiB,MAAO9E,EACP+E,eAAe,IAEjB,IAAKnB,EAAY1H,OACf,SAIF,MAAMoF,KAAEA,EAAFC,OAAQA,GAAWzE,KAAKiH,oBAAoBH,EAAY,IAM9D,MAAO,CAAEM,QAJKpH,KAAKuE,sBAAsBC,EAAMC,GAI7BqC,YAAaA,EAAY,IAG7CG,oBAAoBI,GAClB,IAAIsC,EAAStC,EAAWyB,aAEpBc,YACFA,EADEC,cAEFA,EAFEC,cAMFA,GAGEH,EAEAI,EAAM,IACLF,KAIAC,GAKDE,EAAID,EAAI3K,OAuBZ,MAAO,CAAEqF,OAtBDsF,EACLE,OACC,CAACC,EAAKC,EAAMC,EAAGC,KACb,IAAKzI,EAAGC,GAAKqI,GACRI,EAAIC,GAAMJ,EACf,MAAO,CAACvI,EAAI0I,EAAIzI,EAAI0I,IAEtB,CAAC,EAAG,IAEL9D,IAAKjG,GAAMA,EAAIwJ,GAaDxF,KAHJoF,EAAY,WCxERY,UAAmBnG,EACtCzE,YAAYmD,GACV4D,MAAM5D,GAKErD,aACRM,KAAKsE,YAAcmG,IAGT/K,aAACwD,GAEX,MAAM4D,aAAyBxC,MAAMoG,cACnCC,SAASC,cAAc,UAGzB,IAAK9D,EAAY1H,OACf,SAIF,IAAI4H,EAAOhH,KAAKiH,oBAAoBH,EAAY,KAG5C+D,YAAEA,EAAFC,MAAyDA,GAAU9D,EACnE+D,EAAaF,EAAY,GACzBG,EAAWF,EAAM,GAIjBG,EAAYjL,KAAKkL,cAAcF,EAAUD,EAAY,GAgBrD3D,EAAU,CAAE+D,OAdHnL,KAAKoL,iBAChBJ,EACAD,EACA/K,KAAK+C,OAAOsI,gBACZ,GAUsBC,UAPRtL,KAAKuL,cACnBP,EACAD,EACA/K,KAAK+C,OAAOyI,mBACZ,GAGiCP,UAAAA,GAMnC,MAAO,CAAErC,YAAaxB,EAASA,QAAAA,EAASJ,KAAAA,EAAMF,YAAaA,EAAY,IAIzEG,oBAAoBI,GAElB,MAAMG,QAAEA,EAAFC,YAAWA,GAAgBJ,EAAWwB,YACtCnB,EAAQD,EAAY,GAAKD,EAAQ,GACjCG,EAASF,EAAY,GAAKD,EAAQ,GAIxC,UAASA,QAAAA,EAASE,MAAAA,EAAOC,OAAAA,EAAQlD,OAHlB,CAAC+C,EAAQ,GAAKE,EAAQ,EAAGF,EAAQ,GAAKG,EAAS,IAGlBN,EAAWyB,aAKzDoC,cAAcF,EAAUD,EAAYU,EAAe/G,GACjD,MAAMgH,EAAO,CAAC,IAAK,KAEnB,IAAIC,EP7DR,SAA2BC,GACzB,IAAI5B,EAAI4B,EAAMxM,OAWd,OAVQwM,EACL3B,OACC,CAACC,EAAKC,KACJ,IAAKvI,EAAGC,EAAGgK,GAAK3B,GACXI,EAAIC,EAAIuB,GAAM3B,EACnB,MAAO,CAACvI,EAAI0I,EAAIzI,EAAI0I,EAAIsB,EAAIC,IAE9B,CAAC,EAAG,EAAG,IAERrF,IAAKjG,GAAMA,EAAIwJ,GOkDR+B,CAAkB,CAACf,EAAUD,IAErC,MADW,CAACY,EAAE,GAAKD,EAAK,GAAIC,EAAE,GAAKD,EAAK,IAI1CN,iBAAiBJ,EAAUD,EAAYU,EAAe/G,GACpD,IAAIwE,EAAWhI,EAAoB8J,EAAUD,GAAcrG,EAE3D,OADwB1E,KAAKqF,mBAAmB6D,EAAUuC,GAI5DF,cAAcP,EAAUD,EAAYiB,EAAkBtH,GACpD,IAAIuH,EACA/C,EAAWhI,EAAoB8J,EAAUD,GAAcrG,EAC3D,OAAIwE,EAAW8C,EAAiB,IAAM9C,EAAW8C,EAAiB,SAGlEC,EPlDJ,SAA4B9K,EAAIC,GAC9B,IAKIiJ,GALCvI,EAAIC,GAAMZ,GACVa,EAAIC,GAAMb,EAGX6K,EAAQ5K,KAAKwE,MADP5D,EAAKF,IADLC,EAAKF,IAKf,OADAuI,EAAI4B,EAAQ,EAAIA,EAAQ5K,KAAK6K,GAAKD,EAC3B5K,KAAK6K,GAAK7B,EO0CP8B,CAAmBnB,EAAUD,GAE9BkB,ICpEX,SAASpN,EAASC,GAChB,OAAOA,GAAwB,iBAATA,IAAsBC,MAAMC,QAAQF,GAE5D,SAASsN,EAAQC,EAAQvJ,EAAY5D,EAAQG,GAC3C,GAAIR,EAASK,IAAWL,EAASQ,GAC/B,IAAK,MAAME,KAAOF,EACZR,EAASQ,EAAOE,KACbL,EAAOK,IAAMC,OAAOC,OAAOP,EAAQ,CAAEQ,CAACH,GAAM,KACjD6M,EAAQlN,EAAOK,GAAMF,EAAOE,KAE5BC,OAAOC,OAAOP,EAAQ,CACpBQ,CAACH,GAAM8M,EAAOvJ,EAAYvD,EAAKL,EAAOK,GAAMF,EAAOE,MAM3D,OAAOL,WC/CeoN,EAAoBxJ,GAC1C,MAAO,CAACyJ,EAAiBC,KACvB,IAAI5D,EACA6D,EAwBJ,OAtBE7D,EADE2D,EAAgB3D,YACJwD,EACZM,EACA5J,EACAyJ,EAAgB3D,YAChB4D,EAAmBpF,SAIPoF,EAAmBpF,QAGjCqF,EADEF,EAAgBE,gBACAL,EAChBM,EACA5J,EACAyJ,EAAgBE,gBAChBD,EAAmB1F,aAIH0F,EAAmB1F,iBAIlC0F,GACH5D,YAAAA,EACA6D,gBAAAA,KAKN,SAASC,EAAW5J,EAAYvD,EAAKoN,EAAMC,GACzC,IACIC,EADAC,EAAO,GAEX,GAAIvN,KAAOuD,EAAY,CACrB,IAAIzC,EAAMyC,EAAWvD,GACrB,IAAKc,EAEH,OAAOuM,EAELvM,EAAIyM,OACNA,EAAOzM,EAAIyM,MAETzM,EAAIwM,kBAENA,EAAkBxM,EAAIwM,iBAK1B,GAAI9N,MAAMC,QAAQ2N,GAAO,CACvB,GAAI5N,MAAMC,QAAQ2N,EAAK,IAErB,OAAOA,EAAKlG,IAAI,CAACsG,EAAIC,IAAQN,EAAW5J,EAAYvD,EAAKwN,EAAIH,EAAKI,KAEpE,GAAoB,IAAhBL,EAAKvN,OACP,OAAIyN,EACKA,EAAgBF,EAAMC,EAAME,GAE5BtL,EAAamL,EAAMC,EAAME,GAGpC,GAAoB,IAAhBH,EAAKvN,OACP,OAAIyN,EACKA,EAAgBF,EAAMC,EAAME,GAE5BtL,EAAamL,EAAMC,EAAME,GAItC,MAAoB,iBAATH,EACLE,EACKA,EAAgBF,EAAMC,EAAME,GTNzC,SAAsBG,EAASC,EAAWvL,EAAW,IAGnD,OAAOsL,GAFGC,EAAYD,GAECtL,ESKZwL,CAAaR,EAAMC,EAAME,GAG7BF,EDpFTxJ,QAAQgK,QEWR,MAAMC,EAAgB,CACpBC,MAAO,CACL3K,SAAU,CACRoC,iBAAkB,CAAEnD,EAAG,EAAE,GAAI,IAAKC,EAAG,EAAE,GAAI,KAC3C8C,eAAgB,CAAE/C,EAAG,EAAE,GAAI,IAAKC,EAAG,EAAE,GAAI,MAE3CmB,aAAc,CACZ8D,aAAa,EACbM,SAAS,EAETrH,IAAK,EACLwN,YAAa,IAEbzK,WAAY,CAKV0K,aAAa,GAEf3K,qBACE,OAAOyJ,KAIbmB,KAAM,CACJ9K,SAAU,CACRoC,iBAAkB,CAAEnD,EAAG,EAAE,GAAI,IAAKC,EAAG,EAAE,GAAI,KAC3C8C,eAAgB,CAAE/C,EAAG,EAAE,GAAI,IAAKC,EAAG,EAAE,GAAI,KACzCuH,eAAgB,CAAC,EAAG,IACpBE,aAAc,CAAC,GAAI,KAErBtG,aAAc,CACZjD,IAAK,EACLwN,YAAa,IACbzK,WAAY,CACV0K,aAAa,GAGf3K,qBACE,OAAOyJ,KAIb7B,SAAU,CACR9H,SAAU,CACRoC,iBAAkB,CAAEnD,EAAG,EAAE,GAAI,IAAKC,EAAG,EAAE,GAAI,KAC3C8C,eAAgB,CAAE/C,EAAG,EAAE,GAAI,IAAKC,EAAG,EAAE,GAAI,KACzCwJ,gBAAiB,CAAC,GAAI,KACtBG,mBAAoB,CAAC,IAAK,KAE1BkC,gBAAiB,CAAC,GAAI,KACtBC,gBAAiB,CAAC,GAAI,KACtBC,gBAAiB,CAAC,GAAI,MAExB5K,aAAc,CACZjD,IAAK,EACLwN,YAAa,IACbzK,WAAY,CACV0K,aAAa,GAEf3K,qBACE,OAAOyJ,eCvDSuB,EAAcC,EAAU,IAC9C,IAAI3L,EAAY,GAiBhB,OAdA2L,EAAQtL,QAASuL,IACf,IAAItL,EACJ,GAAsB,iBAAXsL,EACTtL,EAAIuL,EAAYD,EAAQ,MAExB5L,EADW4L,GACOtL,MACb,CACL,IAAIwL,EAAOF,EAAOE,KAClBxL,EAAIuL,EAAYC,EAAMF,EAAOhL,QAC7BZ,EAAU8L,GAAQxL,KAID,IAAIyL,EAAqB/L,GAShD,SAAS6L,EAAYC,EAAMlL,GACzB,IAAIJ,EAEAwL,EAAelP,EAAU,GAAIoO,EAAcY,GAAOlL,GAEtD,OAAQkL,GACN,IAAK,OACHtL,EAAW,IAAI+G,EAAQyE,EAAaxL,UACpC,MACF,IAAK,OACHA,EAAW,IAAIiF,EAAQuG,EAAaxL,UACpC,MACF,IAAK,QACHA,EAAW,IAAI+D,EAASyH,EAAaxL,UACrC,MACF,IAAK,WACHA,EAAW,IAAI6H,EAAW2D,EAAaxL,UAW3C,MAAO,CAAEA,SAAAA,EAAUI,OAAQoL"}